{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f12528-6622-4fb4-8df1-4591172192a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4e5fb2c-3a65-4c1f-ba2a-2f02508b18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DET_PROTOTXT = r\"pretrained_models/deploy.prototxt.txt\"\n",
    "DET_MODEL = r\"pretrained_models/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "REC_MODEL = r\"pretrained_models/face_recognition_sface_2021dec.onnx\"\n",
    "TARGET_IMAGE_FOLDER = \"data/train\"\n",
    "CONFIDENCE_THRESHOLD = 0.5 # Minimum confidence for face detection\n",
    "RECOGNITION_THRESHOLD = 0.9 # Cosine similarity threshold for matching (adjust based on testing)\n",
    "TRACKING_ENABLED = True\n",
    "TRACKER_TYPE = 'csrt' # Options: 'boosting', 'mil', 'kcf', 'tld', 'medianflow', 'mosse', 'csrt'\n",
    "RE_DETECTION_INTERVAL = 30 # Re-run full detection every N frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "706a0941-8fd5-4d5b-aec5-059cc6320c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading face detector model...\n",
      "[INFO] Loading face recognition model...\n",
      "LOADED!!!\n"
     ]
    }
   ],
   "source": [
    "# --- Load Models ---\n",
    "print(\"[INFO] Loading face detector model...\")\n",
    "detector_net = cv2.dnn.readNetFromCaffe(DET_PROTOTXT, DET_MODEL)\n",
    "\n",
    "print(\"[INFO] Loading face recognition model...\")\n",
    "recognizer_net = cv2.dnn.readNetFromONNX(REC_MODEL)\n",
    "print(\"LOADED!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25cc9357-2f9f-43ed-849e-912312fb8e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing target images from data/train...\n",
      "    -> Added embedding from 000_32KV2M6.jpg\n",
      "    -> Added embedding from 0154c130-e3a7-11ef-8450-ff58a15d40df.jpg\n",
      "    -> Added embedding from 01j6a6q2cpj8edb2yk4x.jpg\n",
      "    -> Added embedding from 01jjm4fcqknwbchg19m7.jpg\n",
      "    -> Added embedding from 0x0.jpg\n",
      "    -> Added embedding from 12662-15673171148520-800.jpg\n",
      "    -> Added embedding from 13029.jpg\n",
      "    -> Added embedding from 1540871-871444968.jpg\n",
      "    -> Added embedding from 16591778851898.jpg\n",
      "    -> Added embedding from 1685209582716_4cf037c9-2ce8-4fdd-92e9-a09cc31784d0.jpg\n",
      "    -> Added embedding from 170px-Cristiano_Ronaldo_20120609.jpg\n",
      "    -> Added embedding from 17259965245564.jpg\n",
      "    -> Added embedding from 17354693925699.jpg\n",
      "    -> Added embedding from 1e69762dc1f631ab25142c76e23dbdc971f0b7d5.jpg\n",
      "    -> Added embedding from 220px-Ronaldo_in_2018.jpg\n",
      "    -> Added embedding from 2361280b91e06102378a0edd6aac06ee03c5b83d.jpg\n",
      "    -> Added embedding from 250px-2019-20_Serie_A_-_Torino_v_Juventus_-_Cristiano_Ronald.jpg\n",
      "    -> Added embedding from 2844902-58644068-2560-1440.jpg\n",
      "    -> Added embedding from 36458-zoom.jpg\n",
      "    -> Added embedding from 3f9dfa82-c9ea-4d3f-9522-e54465d4fa2b_alta-libre-aspect-ratio.jpg\n",
      "    -> Added embedding from 3fa00bd0-864a-11ef-ac05-1b95256399e8.jpg\n",
      "    -> Added embedding from 605def5e6746fb0018a73e3d.jpeg\n",
      "    -> Added embedding from 61Fu5SoIQ5L-_AC_UF894-1000_QL80_.jpg\n",
      "    -> Added embedding from 68653.jpg\n",
      "    -> Added embedding from 7075abd83c7089e5f12cfd57488c718a.jpg\n",
      "    -> Added embedding from 7ea71e6114a84a1f8899773887dd8507.jpg\n",
      "    -> Added embedding from 811rL-Pi3zL-_AC_UF1000-1000_QL80_.jpg\n",
      "    -> Added embedding from 8198-1694609670.jpg\n",
      "    -> Added embedding from 8992c6c_2024-06-11t205257z-42074297-up1ek6b1kq5dw-rtrmadp-3-.JPG\n",
      "    -> Added embedding from 8d25427e8e4e05e839749c5bbf2a611a1f86fe3a.jpg\n",
      "    -> Added embedding from 944822_1.jpg\n",
      "    -> Added embedding from 960x0 (1).jpg\n",
      "    -> Added embedding from 960x0.jpg\n",
      "    -> Added embedding from 994800_1.jpg\n",
      "    -> Added embedding from 9ef7a80396b33dff359508afe45c473a.jpg\n",
      "    -> Added embedding from AP090415022483.jpg\n",
      "    -> Added embedding from ap22298283107973-6354e787f659b3a2ef173e743b1637819270f59a.jpg\n",
      "    -> Added embedding from ap22364795346345-153c53713ce57b880428deae9fef9b9926961b6b.jpg\n",
      "    -> Added embedding from b099ded431d1aa08b2669a7fa511f8cc7d17752c.jpg\n",
      "    -> Added embedding from brand_ursu.jpg\n",
      "    -> Added embedding from cr-pr-pic-8-x20250408104128-7864180.jpeg\n",
      "    -> Added embedding from CR7_Discover_Header_1050x1610_3e981306-8ea9-440a-a30e-41303b.jpg\n",
      "    -> Added embedding from cristiano-ronaldo (1).jpg\n",
      "    -> Added embedding from cristiano-ronaldo-al-nassr-2023-1692731063-114594.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-al-nassr.jpg\n",
      "    -> Added embedding from Cristiano-Ronaldo-ceremony-rename-airport-Santa-Cruz-Madeira.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-e1566387799494.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-juventus-1589897013-39110.jpg\n",
      "    -> Added embedding from Cristiano-ronaldo-juventus-2019_-cropped-.jpg\n",
      "    -> Added embedding from Cristiano-Ronaldo-Juventus-COVID-19.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-juventus-sassuolo_pp500y26e7to1xgrq80pwx1y.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-juventus-turin-1595306734-43833.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-juventus-turin-1609744740-53840.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-of-al-nassr-looks-on-as-he-lines-up-prior-.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-of-juventus-gestures-during-the-italian-ch.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-of-manchester-united-in-action-during-uefa.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-of-portugal-reacts-as-he-looks-on-during-n.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-portugal-2024-1718210600-139467.jpg\n",
      "    -> Added embedding from Cristiano-Ronaldo-Portugal-ball-World-Cup-2010-September-9-2.jpg\n",
      "    -> Added embedding from cristiano-ronaldo-real-madrid-play-barcelona-during-la-liga-.jpg\n",
      "    -> Added embedding from cristiano-ronaldo.jpg\n",
      "    -> Added embedding from Cristiano_Ronaldo-_2023.jpg\n",
      "    -> Added embedding from Cristiano_Ronaldo_2018.jpg\n",
      "    -> Added embedding from cristiano_ronaldo_after_scoring_his_and_real_madrid_s_second.jpeg\n",
      "    -> Added embedding from cristiano_ronaldo_of_portugal_celebrates_after_scoring_a.jpeg\n",
      "    -> Added embedding from Cristiano_Ronaldo_playing_for_Al_Nassr_FC_against_Persepolis.jpg\n",
      "    -> Added embedding from Cristiano_Ronaldo_WC2022_-_01_-cropped-.jpg\n",
      "    -> Added embedding from cs59l5uo_cristiano-ronaldo-afp_625x300_13_September_24.jpg\n",
      "    -> Added embedding from d3e7bf2563ddcb0d528a19c015beeab1.jpg\n",
      "    -> Added embedding from depositphotos_361206330-stock-photo-cristiano-ronaldo-juvent.jpg\n",
      "    -> Added embedding from ec8b6c6d23807667552169928e2e99bab62e765a.jpg\n",
      "    -> Added embedding from fce1bd670c0fbec59b3b353037725078.jpeg\n",
      "    -> Added embedding from gdfg.jpeg\n",
      "    -> Added embedding from GettyImages-1247954164.jpg\n",
      "    -> Added embedding from GettyImages-1443193307.jpg\n",
      "    -> Added embedding from GettyImages-1734016483-e1726177787958.jpg\n",
      "    -> Added embedding from gtrhtr.jpeg\n",
      "    -> Added embedding from image (10).jpeg\n",
      "    -> Added embedding from image (11).jpeg\n",
      "    -> Added embedding from image (12).jpeg\n",
      "    -> Added embedding from image (13).jpeg\n",
      "    -> Added embedding from image (14).jpeg\n",
      "    -> Added embedding from image (15).jpeg\n",
      "    -> Added embedding from image (16).jpeg\n",
      "    -> Added embedding from image (17).jpeg\n",
      "    -> Added embedding from image (3).jpeg\n",
      "    -> Added embedding from image (5).jpeg\n",
      "    -> Added embedding from image (6).jpeg\n",
      "    -> Added embedding from image (7).jpeg\n",
      "    -> Added embedding from image (8).jpeg\n",
      "    -> Added embedding from image (9).jpeg\n",
      "    -> Added embedding from image.jpeg\n",
      "    -> Added embedding from images (10).jpeg\n",
      "    -> Added embedding from images (11).jpeg\n",
      "    -> Added embedding from images (13).jpeg\n",
      "    -> Added embedding from images (14).jpeg\n",
      "    -> Added embedding from images (15).jpeg\n",
      "    -> Added embedding from images (16).jpeg\n",
      "    -> Added embedding from images (18).jpeg\n",
      "    -> Added embedding from images (21).jpeg\n",
      "    -> Added embedding from images (7).jpeg\n",
      "    -> Added embedding from images (9).jpeg\n",
      "    -> Added embedding from images.jpeg\n",
      "    -> Added embedding from juventus-cristiano-ronaldo-celebrates-scoring-his-sides-firs.jpg\n",
      "    -> Added embedding from juventus-cristiano-ronaldo-during-the-uefa-champions-league-.jpg\n",
      "    -> Added embedding from kjh.jpeg\n",
      "    -> Added embedding from latest.jpeg\n",
      "    -> Added embedding from Legends-Profile_Cristiano-Ronaldo1523460877263.jpg\n",
      "    -> Added embedding from maxresdefault.jpg\n",
      "    -> Added embedding from MV5BZjY3NzcwODYtMTQ0My00MzY1LWIzOGUtOWEzNjk2YWIwZDY1XkEyXkFq.jpg\n",
      "    -> Added embedding from rer.jpeg\n",
      "    -> Added embedding from resizedcrop-c64184fbcb5a459e364a83416f4bf2ee-840x630.jpg\n",
      "    -> Added embedding from ronaldo-juve-goal.jpg\n",
      "    -> Added embedding from RONALDO-NEW-JERSEY-AP.jpg\n",
      "    -> Added embedding from ronaldo-sponsored.jpg\n",
      "    -> Added embedding from rs_634x1024-190109152450-634x1024-cristianoronaldo-gj-1-9-19.jpg\n",
      "    -> Added embedding from russland-moskau-moscow-uefa-champions-league-saison-2007-new.jpg\n",
      "    -> Added embedding from skynews-cristiano-ronaldo-ronaldo_5975830.jpg\n",
      "    -> Added embedding from skysports-cristiano-ronaldo_4510781.jpg\n",
      "    -> Added embedding from skysports-cristiano-ronaldo_5050722.jpg\n",
      "    -> Added embedding from Soccer-forward-Cristiano-Ronaldo-2018.jpg\n",
      "    -> Added embedding from SOCCER-SAUDI-HIL-NSR-REPORT-32_1744090935355_1744090943459.JPG\n",
      "    -> Added embedding from stock_GettyImages-1475637304_uqmji7.jpeg\n",
      "    -> Added embedding from wq.jpg\n",
      "    -> Added embedding from x4mgjhpm4ltlml0lxwwr.jpeg\n",
      "    -> Added embedding from _106066040_ronaldo_epa.jpg\n",
      "[INFO] Generated 126 target embeddings.\n"
     ]
    }
   ],
   "source": [
    "target_embeddings = []\n",
    "print(f\"[INFO] Processing target images from {TARGET_IMAGE_FOLDER}...\")\n",
    "\n",
    "for image_name in os.listdir(TARGET_IMAGE_FOLDER):\n",
    "    image_path = os.path.join(TARGET_IMAGE_FOLDER, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Warning: Could not read image {image_path}\")\n",
    "        continue\n",
    "\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # 1. Detect face(s) in the target image\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    detector_net.setInput(blob)\n",
    "    detections = detector_net.forward()\n",
    "\n",
    "    # Assume the largest face is the target if multiple are found\n",
    "    best_face_confidence = -1\n",
    "    best_face_box = None\n",
    "\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > CONFIDENCE_THRESHOLD:\n",
    "            # Get bounding box, ensuring it's within image bounds\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            startX = max(0, startX)\n",
    "            startY = max(0, startY)\n",
    "            endX = min(w - 1, endX)\n",
    "            endY = min(h - 1, endY)\n",
    "\n",
    "            # Basic check for valid box size\n",
    "            if endX > startX and endY > startY:\n",
    "                # Keep track of the most confident face detection\n",
    "                if confidence > best_face_confidence:\n",
    "                    best_face_confidence = confidence\n",
    "                    best_face_box = (startX, startY, endX, endY)\n",
    "\n",
    "    # 2. Extract embedding if a face was found\n",
    "    if best_face_box is not None:\n",
    "        (startX, startY, endX, endY) = best_face_box\n",
    "        face_roi = image[startY:endY, startX:endX]\n",
    "\n",
    "        if face_roi.size == 0:\n",
    "            print(f\"Warning: Empty face ROI extracted from {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Preprocess face for recognition model (specific to SFace)\n",
    "        face_blob = cv2.dnn.blobFromImage(face_roi, 1.0 / 127.5, (112, 112), (127.5, 127.5, 127.5), swapRB=True)\n",
    "        recognizer_net.setInput(face_blob)\n",
    "        embedding = recognizer_net.forward()\n",
    "        target_embeddings.append(embedding.flatten()) # Store the flattened embedding vector\n",
    "        print(f\"    -> Added embedding from {image_name}\")\n",
    "    else:\n",
    "        print(f\"Warning: No face detected in {image_path} above threshold {CONFIDENCE_THRESHOLD}\")\n",
    "\n",
    "if not target_embeddings:\n",
    "    print(\"[ERROR] No target embeddings generated. Check target images and detection settings.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"[INFO] Generated {len(target_embeddings)} target embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37613a21-9228-47e7-a635-17f0c55bbf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting video processing from data/test/vid1.mp4...\n",
      "[INFO] Output video will be saved to data/test/vid1_PROCESSED_TRACKED.mp4\n",
      "[INFO] End of video stream.\n",
      "[INFO] Cleaning up...\n",
      "[INFO] Finished.\n"
     ]
    }
   ],
   "source": [
    "# --- Video Processing ---\n",
    "VIDEO_SOURCE = \"data/test/vid1.mp4\" # Or 0 for webcam\n",
    "OUTPUT_VIDEO_PATH = \"data/test/vid1_PROCESSED_TRACKED.mp4\" # Optional: Save output\n",
    "BLUR_KERNEL_SIZE = (99, 99) # Must be odd numbers; larger means more blur\n",
    "\n",
    "print(f\"[INFO] Starting video processing from {VIDEO_SOURCE}...\")\n",
    "cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "\n",
    "# Optional: Setup Video Writer\n",
    "writer = None\n",
    "if OUTPUT_VIDEO_PATH:\n",
    "    try:\n",
    "        # Get video properties for the writer\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        # Define the codec and create VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Or 'XVID', 'MJPG', etc.\n",
    "        writer = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (frame_width, frame_height))\n",
    "        print(f\"[INFO] Output video will be saved to {OUTPUT_VIDEO_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Could not initialize video writer: {e}\")\n",
    "        writer = None\n",
    "\n",
    "# Cosine Similarity function\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0 # Avoid division by zero\n",
    "    return np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)\n",
    "\n",
    "# Initialize tracker\n",
    "tracker = None\n",
    "target_tracked = False\n",
    "frame_count = 0\n",
    "target_bbox = None\n",
    "\n",
    "def create_tracker(tracker_type):\n",
    "    if tracker_type == 'boosting':\n",
    "        return cv2.legacy.TrackerBoosting_create()\n",
    "    elif tracker_type == 'mil':\n",
    "        return cv2.legacy.TrackerMIL_create()\n",
    "    elif tracker_type == 'kcf':\n",
    "        return cv2.legacy.TrackerKCF_create()\n",
    "    elif tracker_type == 'tld':\n",
    "        return cv2.legacy.TrackerTLD_create()\n",
    "    elif tracker_type == 'medianflow':\n",
    "        return cv2.legacy.TrackerMedianFlow_create()\n",
    "    elif tracker_type == 'mosse':\n",
    "        return cv2.legacy.TrackerMOSSE_create()\n",
    "    elif tracker_type == \"csrt\":\n",
    "        return cv2.legacy.TrackerCSRT_create()\n",
    "    else:\n",
    "        print(\"Invalid tracker type. Using CSRT by default.\")\n",
    "        return cv2.legacy.TrackerCSRT_create()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"[INFO] End of video stream.\")\n",
    "        break\n",
    "\n",
    "    (h, w) = frame.shape[:2]\n",
    "\n",
    "    if not TRACKING_ENABLED or not target_tracked or (frame_count % RE_DETECTION_INTERVAL == 0):\n",
    "        # Perform face detection and recognition\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        detector_net.setInput(blob)\n",
    "        detections = detector_net.forward()\n",
    "\n",
    "        best_match_confidence = -1\n",
    "        best_match_box = None\n",
    "        matched_target = False\n",
    "\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "            if confidence > CONFIDENCE_THRESHOLD:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                startX = max(0, startX)\n",
    "                startY = max(0, startY)\n",
    "                endX = min(w - 1, endX)\n",
    "                endY = min(h - 1, endY)\n",
    "\n",
    "                if endX > startX and endY > startY:\n",
    "                    face_roi = frame[startY:endY, startX:endX]\n",
    "                    if face_roi.size == 0: continue\n",
    "\n",
    "                    face_blob = cv2.dnn.blobFromImage(face_roi, 1.0 / 127.5, (112, 112), (127.5, 127.5, 127.5), swapRB=True)\n",
    "                    recognizer_net.setInput(face_blob)\n",
    "                    current_embedding = recognizer_net.forward().flatten()\n",
    "\n",
    "                    for target_emb in target_embeddings:\n",
    "                        similarity = cosine_similarity(current_embedding, target_emb)\n",
    "                        if similarity > RECOGNITION_THRESHOLD:\n",
    "                            matched_target = True\n",
    "                            best_match_box = (startX, startY, endX - startX, endY - startY) # Tracker needs (x, y, w, h)\n",
    "                            target_tracked = True\n",
    "                            if TRACKING_ENABLED:\n",
    "                                tracker = create_tracker(TRACKER_TYPE)\n",
    "                                tracker.init(frame, best_match_box)\n",
    "                            break # Target found, no need to check other embeddings\n",
    "                    if matched_target:\n",
    "                        break # Target found, no need to check other detections\n",
    "\n",
    "        if not matched_target:\n",
    "            target_tracked = False\n",
    "            target_bbox = None\n",
    "\n",
    "    elif TRACKING_ENABLED and target_tracked and tracker is not None:\n",
    "        # Track the target\n",
    "        success, bbox = tracker.update(frame)\n",
    "        if success:\n",
    "            (x, y, w_track, h_track) = [int(v) for v in bbox]\n",
    "            target_bbox = (x, y, x + w_track, y + h_track)\n",
    "        else:\n",
    "            target_tracked = False\n",
    "            target_bbox = None\n",
    "            tracker = None # Reset tracker if tracking fails\n",
    "\n",
    "    # Apply blurring if target is identified or tracked\n",
    "    if target_tracked and target_bbox is not None:\n",
    "        startX, startY, endX, endY = target_bbox\n",
    "        face_roi = frame[startY:endY, startX:endX]\n",
    "        if face_roi.size > 0:\n",
    "            blurred_face = cv2.GaussianBlur(face_roi, (BLUR_KERNEL_SIZE[0] // 2 * 2 + 1, BLUR_KERNEL_SIZE[1] // 2 * 2 + 1), 0) # Ensure odd kernel size\n",
    "            frame[startY:endY, startX:endX] = blurred_face\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2) # Red box for target\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Write frame to output video (if writer is initialized)\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "\n",
    "    # Exit condition\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# --- Cleanup ---\n",
    "print(\"[INFO] Cleaning up...\")\n",
    "cap.release()\n",
    "if writer is not None:\n",
    "    writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"[INFO] Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9eec4-118b-4331-b20f-710eb3a3063f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac232f4d-6f43-4b98-9acd-f40be8c0c6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b271f-2cd8-4522-bd5f-ffa9be5f5357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617926c-7a63-4192-a70d-faf94258763f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
